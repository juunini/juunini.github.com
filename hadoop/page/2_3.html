비행기 이착륙 지연 데이터를 받을건데요<br>
저번에 제가 쉘스크립트 언급한적이 있잖아요?<br>
책에서 반복문을 통해서 알아서 다운로드 받고 압축을 푸는 쉘스크립트를 써뒀더라구요.<br>
책에는 여기에 받으세요~ 했는데 우리는 다른데 저장합시다.<br>
<color4>hadoop-examples</color4> 폴더에 <color4>airplain</color4> 이라는 폴더를 만들어주세요.<br>
그리고 <color4>airplain</color4> 폴더에 <color4>download.sh</color4> 라는 파일을 만들고 내용을 아래처럼 입력해주세요.<br>

<terminal>
<blur><i>#! /bin/sh</i></blur>

<color4>for</color4> <color7>((</color7>i = <color2>1987</color2> <color7>; i</color7> <= <color2>2008</color2> <color7>; i</color7>++<color7>))</color7> <color4>do</color4>
    wget http://stat-computing.org/dataexpo/2009/$i.csv.bz2
    bzip2 -d $i.csv.bz2
    sed -e <color7>'1d'</color7> $i.csv > $i_temp.csv
    mv $i_temp.csv $i.csv
<color4>done</color4>
</terminal>

첫줄에 <blur><i>#! /bin/sh</i></blur> 은 쉘스크립트 라고 하는 주석 선언문입니다.<br>
for 문은 다들 좀 친숙하시죠? 1989년도 데이터부터 2008년도 데이터까지 받겠다는 의미입니다.<br>
<color4>$i</color4> 는 아마도 파이썬이나 루비에서 <color4>{$i}</color4> 하고 변수를 입력하는 의미인가봅니다.<br>
다운받고, 압축 풀고, sed -e 는 파일의 다중편집 명령어입니다. 파일 안에 '1d' 라는 단어가 temp가 더 적으면 temp를 $i로 바꾸라는 명령어입니다.<br>
사실 뭔지 잘 모르겠습니다. bz2 파일 안에 2008.csv 와 2008_temp.csv 파일이 같이 있는데 비교하는 것 같습니다.<br>
쨋든 작가가 친절하게 써놨으니 그냥 이렇게 해보죠.<br>
일단 터미널로 해당 폴더 경로로 들어가주세요... 아니 그냥 제가 밑에 써드릴게요.<br>

<terminal>
<strong>[hadoop@namenode ~]$</strong> cd /home/hadoop/hadoop-examples/airplain
<strong>[hadoop@namenode airplain]$</strong> sudo chmod -R 777 download.sh
<strong>[hadoop@namenode airplain]$</strong> ./download.sh
</terminal>

다 받는데 좀 걸릴겁니다.<br>
한 30분 쉬고오시죠 ^^;<br>
<br>
다 되고나면 다운로드 받은 파일을 HDFS로 옮겨야 합니다.<br>

<terminal>
<strong>[hadoop@namenode ~]$</strong> cd $HADOOP_HOME
</terminal>

혹시나 이렇게 했는데 하둡 폴더로 가지 않으면 <color4>source /etc/profile</color4> 하고 한번 입력해주세요.<br>

<terminal>
<strong>[hadoop@namenode ~]$</strong> cd $HADOOP_HOME
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop fs -mkdir airplain
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop fs -put /home/hadoop/hadoop-examples/airplain/*.csv airplain
<blur>(한참 걸림 좀 쉬고 오세요.)</blur>
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop fs -ls airplain
Found 22 items
-rw-r--r--   3 hadoop supergroup  127162642 2018-01-27 02:41 /user/hadoop/airplain/1987.csv
-rw-r--r--   3 hadoop supergroup  501039172 2018-01-27 02:41 /user/hadoop/airplain/1988.csv
-rw-r--r--   3 hadoop supergroup  486518521 2018-01-27 02:41 /user/hadoop/airplain/1989.csv
-rw-r--r--   3 hadoop supergroup  509194387 2018-01-27 02:41 /user/hadoop/airplain/1990.csv
-rw-r--r--   3 hadoop supergroup  491209793 2018-01-27 02:42 /user/hadoop/airplain/1991.csv
-rw-r--r--   3 hadoop supergroup  492313431 2018-01-27 02:42 /user/hadoop/airplain/1992.csv
-rw-r--r--   3 hadoop supergroup  490753352 2018-01-27 02:43 /user/hadoop/airplain/1993.csv
-rw-r--r--   3 hadoop supergroup  501558365 2018-01-27 02:43 /user/hadoop/airplain/1994.csv
-rw-r--r--   3 hadoop supergroup  530751268 2018-01-27 02:43 /user/hadoop/airplain/1995.csv
-rw-r--r--   3 hadoop supergroup  533922063 2018-01-27 02:44 /user/hadoop/airplain/1996.csv
-rw-r--r--   3 hadoop supergroup  540347561 2018-01-27 02:44 /user/hadoop/airplain/1997.csv
-rw-r--r--   3 hadoop supergroup  538432575 2018-01-27 02:45 /user/hadoop/airplain/1998.csv
-rw-r--r--   3 hadoop supergroup  552925722 2018-01-27 02:46 /user/hadoop/airplain/1999.csv
-rw-r--r--   3 hadoop supergroup  570151313 2018-01-27 02:46 /user/hadoop/airplain/2000.csv
-rw-r--r--   3 hadoop supergroup  600411162 2018-01-27 02:47 /user/hadoop/airplain/2001.csv
-rw-r--r--   3 hadoop supergroup  530506713 2018-01-27 02:48 /user/hadoop/airplain/2002.csv
-rw-r--r--   3 hadoop supergroup  626744942 2018-01-27 02:48 /user/hadoop/airplain/2003.csv
-rw-r--r--   3 hadoop supergroup  669878813 2018-01-27 02:49 /user/hadoop/airplain/2004.csv
-rw-r--r--   3 hadoop supergroup  671026965 2018-01-27 02:50 /user/hadoop/airplain/2005.csv
-rw-r--r--   3 hadoop supergroup  672067796 2018-01-27 02:51 /user/hadoop/airplain/2006.csv
-rw-r--r--   3 hadoop supergroup  702877893 2018-01-27 02:51 /user/hadoop/airplain/2007.csv
-rw-r--r--   3 hadoop supergroup  689413044 2018-01-27 02:52 /user/hadoop/airplain/2008.csv
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop fs -cat airplain/2008.csv
<blur>(주루루룩.... 적당히 봤으면 Ctrl + C 눌러주세요.)</blur>
</terminal>

복사 하고나면.... 여러분 여기서 잘 생각해보세요. 저 데이터가 12GB였죠? HDFS(하둡 파일 시스템)으로 12GB를 복사했으면... 총 24기가이고,<br>
굳이 HDFS로 복사한 파일을 또 로컬에 갖고 있을 필요도 없습니다.<br>
용량 낭비죠. 그러니 로컬에 있는 12기가의 파일은 전부 삭제하도록 하겠습니다.<br>
아래 명령어를 입력해주세요.<br>

<terminal>
<strong>[hadoop@namenode hadoop]$</strong> cd /home/hadoop/hadoop-examples/airplain
<strong>[hadoop@namenode airplain]$</strong> rm *.csv
</terminal>

파일을 지웠을 뿐인데 로컬 용량에 12GB가 생겼습니다.(?)<br>
조삼모사같지만 그렇게 생각해주세요. 쨋든 로컬에 갖고 있을 필요는 없잖아요.<br>
만약 여러분 컴퓨터의 용량이 충분하지 않다면 갑자기 가상머신이 순서대로 뻗다가 컴퓨터도 뻗는 경우가 생깁니다.<br>
<color7>용량이 모자라서</color7> 거든요... 제가 경험해서 그러는겁니다.<br>
<br>
이제 파일 분석을 시작합시다.<br>
여러분은 지웠지만 저는 아직 안지웠어요.(?)<br>
파일이 어떤식으로 되있는지 보여드릴게요.<br>

<img src="/hadoop/img2/3_1.jpg" alt="">

파일들이 콤마 단위로 테이블화 되어있는것을 확인할 수 있습니다.<br>
각각이 뭔지 하나씩 보겠습니다. 배열로 인식하여 쓰도록 하겠습니다. 첫번째 컬럼은 [0] 이런식으로요.<br>
<br>
[0] : 년도 입니다.<br>
[1] : 월 입니다.<br>
[2] : 일 입니다.<br>
[3] : ??뭔지 모르겠습니다. 10 이하의 숫자가 쓰여져 있는데 짐작이 안가네요.<br>
[4] : ?? 700대의 숫자가 쓰여있습니다.....이것과 아래 3개 중 뭔가가 승객 수 일 것 같네요.<br>
[5] : ?? 700대의 숫자가 쓰여있습니다.<br>
[6] : ?? 900대의 근접한 숫자가 쓰여있습니다.<br>
[7] : ?? 800대의 숫자가 쓰여있습니다.<br>
[8] : PS...?? 항공사 코드라고 합니다.<br>
[9] : 1451....?? 경로 번호?<br>
[10] : NA.....??<br>
[11] : 70 ~ 90 대의 숫자가 쓰여있습니다.<br>
[12] : 70 ~ 90 대의 숫자가 쓰여있습니다.<br>
[13] : NA.....??<br>
[14] : 양수 일 때도 있고 음수 일 떄도 있고....?? 도착 지연시간이라고 합니다. 양수는 지연, 음수는 빨리 도착한건가?<br>
[15] : 양수 일 때도 있고 음수 일 떄도 있고....?? 출발 지연시간이라고 합니다. 양수는 지연, 음수는 빨리 출발한건가?<br>
[16] : SAN...도착지?<br>
[17] : SFO...출발지?<br>
[18] : 447....운항거리 라고 합니다..<br>
[19] : NA.....??<br>
[20] : NA.....??<br>
[21] : 0<br>
[22] : NA.....??<br>
[23] : 0<br>
[24] : NA.....??<br>
[25] : NA.....??<br>
[26] : NA.....??<br>
[27] : NA.....??<br>
[28] : NA.....??<br>
<br>
일단 책에 나와있는 코드와 이걸 대조했을 때 우리가 정확히 알아낼 수 있는건<br>
[0] 년도, [1] 월, [2] 일, [8] 항공사 코드, [14] 도착 지연시간, [15] 출발 지연시간, [16] 도착지?, [17] 출발지? [18] 운항거리<br>
이렇게 알 수 있습니다.<br>
<br>
알아냈으니 책에 나와있는대로가 아닌 제 입맛대로 코드를 바꿔서 짜보도록 하겠습니다.<br>
여러분, 책에 뭔가 나와있는데 잘 모를때는 앵무새처럼 따라해보는것도 나쁘진 않지만, 어느정도 알게되면<br>
무조건 따라하기보단 응용을 해보는것도 나쁘진 않아요.<br>
<br>
그러니 책에 나온대로 년, 월만 비교해서 일치하는걸 찾아내는게 아니라<br>
사실 제대로 분석하려면 일, 시간별로 출발지, 도착지, 항공사별로 구분해야겠지만...<br>
이걸 일로 하는거면 그래야겠지만 실습이니까 그렇게까진 하지 말고<br>
<br>
<color2>출발 지연</color2> 시에는 [년, 월, 출발지]를 키에 넣기로 하고,<br>
<color2>도착 지연</color2> 시에는 [년, 월, 도착지]를 키에 넣겠습니다.<br>
어느 출발지에서 출발 지연이 자주 일어나는지,<br>
어느 도착지에서 도착 지연지 자주 일어나는지를 분석하겠다는 뜻 입니다.<br>
<br>
<color4>AirlineMapper.java</color4>

<terminal>
<color4>import</color4> <color2>java.io.IOException;</color2>

<color4>import</color4> <color2>org.apache.hadoop.io.IntWritable;</color2>
<color4>import</color4> <color2>org.apache.hadoop.io.LongWritable;</color2>
<color4>import</color4> <color2>org.apache.hadoop.io.Text;</color2>
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.Mapper;</color2>

<color2>public</color2> <color2>class</color2> AirlineMapper <color2>extends</color2> <color4>Mapper</color4>&lt;<color2>LongWritable</color2>, <color2>Text</color2>, <color2>Text</color2>, <color2>IntWritable</color2>&gt; {

    <color2>private</color2> <color2>IntWritable</color2> outputValue = <color6>new</color6> <color3>IntWritable</color3>(<color2>1</color2>);
    <color2>private</color2> <color2>Text</color2> outputKey = <color6>new</color6> <color3>Text</color3>();

    <color2>public</color2> <color2>void</color2> <color3>map</color3>(<color2>LongWritable</color2> <blur>key</blur>, <color2>Text</color2> <blur>value</blur>, <color2>Context</color2> <blur>context</blur>) <color2>throws</color2> <color2>IOException</color2>, <color2>InterruptedException</color2> {

        <color2>String</color2>[] column = <color4>value</color4>.<color3>toString</color3>().<color3>split</color3>(<color7>","</color7>);

        <blur><i>// 년[0], 월[1], 일[2], 출발지[17], 도착지[16]</i></blur>

        <color6>if</color6> (!column[<color2>15</color2>].<color3>equals</color3>(<color7>"NA"</color7>) && <color4>Integer</color4>.<color3>parseInt</color3>(column[<color2>15</color2>]) <color2>> 0</color2>) {  <blur><i>// 출발 지연일 때</i></blur>
            <color4>outputKey</color4>.<color3>set</color3>(<color7>"D"</color7> + <color7>","</color7> + <color4>Integer</color4>.<color3>parseInt</color3>(column[<color2>0</color2>]) + <color7>","</color7> + <color4>Integer</color4>.<color3>parseInt</color3>(column[<color2>1</color2>]) + <color7>","</color7> + column[<color2>17</color2>]);
            <color4>context</color4>.<color3>write</color3>(outputKey, outputValue);
        } <color6>else if</color6> (!column[<color2>14</color2>].<color3>equals</color3>(<color7>"NA"</color7>) && <color4>Integer</color4>.<color3>parseInt</color3>(column[<color2>14</color2>]) <color2>> 0</color2>) {  <blur><i>// 도착 지연일 때</i></blur>
            <color4>outputKey</color4>.<color3>set</color3>(<color7>"A"</color7> + <color7>","</color7> + <color4>Integer</color4>.<color3>parseInt</color3>(column[<color2>0</color2>]) + <color7>","</color7> + <color4>Integer</color4>.<color3>parseInt</color3>(column[<color2>1</color2>]) + <color7>","</color7> + column[<color2>16</color2>]);
            <color4>context</color4>.<color3>write</color3>(outputKey, outputValue);
        }
    }
}
</terminal>

<color4>AirlineReducer.java</color4>

<terminal>
<color4>import</color4> <color2>java.io.IOException;</color2>

<color4>import</color4> <color2>org.apache.hadoop.io.IntWritable;</color2>
<color4>import</color4> <color2>org.apache.hadoop.io.Text;</color2>
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.Reducer;</color2>
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;</color2>

<color2>public</color2> <color2>class</color2> AirlineReducer <color2>extends</color2> <color2>Reducer</color2>&lt;<color2>Text</color2>, <color2>IntWritable</color2>, <color2>Text</color2>, <color2>IntWritable</color2>&gt; {
    <color2>private</color2> <color2>MultipleOutputs</color2>&lt;<color2>Text</color2>, <color2>IntWritable</color2>&gt; mos;
    <color2>private</color2> <color2>Text</color2> outputKey = <color6>new</color6> <color3>Text</color3>();
    <color2>private</color2> <color2>IntWritable</color2> result = <color6>new</color6> <color3>IntWritable</color3>();

    <color2>@Override</color2>  <blur><i> // Reducer 클래스의 setup 함수를 오버라이드 합니다. 멀티파일로 저장해야 하기 때문이니까요.</i></blur>
    <color2>public</color2> <color2>void</color2> <color3>setup</color3>(<color2>Context</color2> context) <color2>throws</color2> <color2>IOException</color2>, <color2>InterruptedException</color2> {
        mos = <color6>new</color6> <color2>MultipleOutputs</color2>&lt;<color2>Text</color2>, <color2>IntWritable</color2>&gt;(context);
    }

    <color2>public</color2> <color2>void</color2> <color3>reduce</color3>(<color2>Text</color2> <blur>key</blur>, <color2>Iterable</color2>&lt;<color2>IntWritable</color2>&gt; <blur>values</blur>, <color2>Context</color2> <blur>context</blur>) <color2>throws</color2> <color2>IOException</color2>, <color2>InterruptedException</color2> {
        <color2>String</color2>[] column = <color2>key</color2>.<color3>toString</color3>().<color3>split</color3>(<color7>","</color7>);
        <color2>outputKey</color2>.set(column[1] + <color7>"\t"</color7> + column[2] + <color7>"\t"</color7> + column[3]); <blur><i>// [0]은 출발지연과 도착지연 구분자이기 때문에 키에서 빼버림</i></blur>

        <color6>if</color6> (column[0].<color3>equals</color3>(<color7>"D"</color7>)) {  <blur><i>// 출발 지연</i></blur>
            <color2>int</color2> sum = 0;
            <color6>for</color6> (<color2>IntWritable</color2> value : values) {
                sum += <color2>value</color2>.<color3>get</color3>();
            }
            <color2>result</color2>.<color3>set</color3>(sum);
            <color2>mos</color2>.<color3>write</color3>(<color7>"departure"</color7>, outputKey, result);  <blur><i>// departure 라는 이름으로 보냄</i></blur>
        } <color6>else</color6> {    <blur><i>// 도착 지연</i></blur>
            <color2>int</color2> sum = 0;
            <color6>for</color6> (<color2>IntWritable</color2> value : values) {
                sum += <color2>value</color2>.<color3>get</color3>();
            }
            <color2>result</color2>.<color3>set</color3>(sum);
            <color2>mos</color2>.<color3>write</color3>(<color7>"arrival"</color7>, outputKey, result);    <blur><i>// arrival 라는 이름으로 보냄</i></blur>
        }
    }

    <color2>@Override</color2>   <blur><i>// Reducer클래스의 cleanup함수를 오버라이드 합니다. 멀티파일을 종료시켜야지요.</i></blur>
    <color2>public</color2> <color2>void</color2> <color3>cleanup</color3>(<color2>Context</color2> context) <color2>throws</color2> <color2>IOException</color2>, <color2>InterruptedException</color2> {
        <color2>mos</color2>.<color3>close</color3>();
    }
}
</terminal>

<color4>AirlineCount.java</color4>

<terminal>
<color4>import</color4> <color2>org.apache.hadoop.conf.Configuration;</color2>
<color4>import</color4> <color2>org.apache.hadoop.conf.Configured;</color2>
<color4>import</color4> <color2>org.apache.hadoop.fs.Path;</color2>
<color4>import</color4> <color2>org.apache.hadoop.io.Text;</color2>
<color4>import</color4> <color2>org.apache.hadoop.io.IntWritable;</color2>
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.Job;</color2>
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</color2>
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.lib.input.TextInputFormat;</color2>
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</color2>
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;</color2>
<color4>import</color4> <color2>org.apache.hadoop.util.GenericOptionsParser;</color2>
<color4>import</color4> <color2>org.apache.hadoop.util.Tool;</color2>
<color4>import</color4> <color2>org.apache.hadoop.util.ToolRunner;</color2>
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;</color2>

<color2>public</color2> <color2>class</color2> AirlineCount <color2>extends</color2> <color4>Configured</color4> <color2>implements</color2> <color4>Tool</color4> {

    <color2>public</color2> <color2>static</color2> <color2>void</color2> <color3>main</color3>(<color2>String</color2>[] args) <color2>throws</color2> <color2>Exception</color2> {
        <color2>int</color2> res = <color4>ToolRunner</color4>.<color3>run</color3>(<color6>new</color6> <color3>Configuration</color3>(), <color6>new</color6> <color3>AirlineCount</color3>(), args);
        <color4>System</color4>.<color4>out</color4>.<color3>println</color3>(<color7>"Result : "</color7> + res);
    }

    <color2>public</color2> <color2>int</color2> <color3>run</color3>(<color2>String</color2>[] args) <color2>throws</color2> <color2>Exception</color2> {

        <color6>if</color6> (<color4>args</color4>.length <color2>!= 2</color2>) {
            <color4>System</color4>.<color4>err</color4>.<color3>println</color3>(<color7>"Usage: AirlineCount &lt;input&gt; &lt;output&gt;"</color7>);
            <color4>System</color4>.<color3>exit</color3>(<color2>2</color2>);
        }

        <color2>Job</color2> job = <color6>new</color6> <color3>Job</color3>(<color3>getConf</color3>(), <color7>"AirlineCount"</color7>);
        <color4>job</color4>.<color3>setJarByClass</color3>(<color4>AirlineCount</color4>.class);
        <color4>job</color4>.<color3>setMapperClass</color3>(<color4>AirlineMapper</color4>.class);
        <color4>job</color4>.<color3>setReducerClass</color3>(<color4>AirlineReducer</color4>.class);

        <color4>job</color4>.<color3>setInputFormatClass</color3>(<color4>TextInputFormat</color4>.class);
        <color4>job</color4>.<color3>setOutputFormatClass</color3>(<color4>TextOutputFormat</color4>.class);

        <color4>job</color4>.<color3>setOutputKeyClass</color3>(<color4>Text</color4>.class);
        <color4>job</color4>.<color3>setOutputValueClass</color3>(<color4>IntWritable</color4>.class);

        <color4>FileInputFormat</color4>.<color3>addInputPath</color3>(job, <color6>new</color6> <color3>Path</color3>(args[<color2>0</color2>]));
	    <color4>FileOutputFormat</color4>.<color3>setOutputPath</color3>(job, <color6>new</color6> <color3>Path</color3>(args[<color2>1</color2>]));
        
        <color4>MultipleOutputs</color4>.<color3>addNamedOutput</color3>(job, <color7>"departure"</color7>, <color4>TextOutputFormat</color4>.class, <color4>Text</color4>.class, <color4>IntWritable</color4>.class);    <blur><i>// departure로 시작하는 파일을 생성하여 저장함</i></blur>
        <color4>MultipleOutputs</color4>.<color3>addNamedOutput</color3>(job, <color7>"arrival"</color7>, <color4>TextOutputFormat</color4>.class, <color4>Text</color4>.class, <color4>IntWritable</color4>.class);      <blur><i>// arrival로 시작하는 파일을 생성하여 저장함</i></blur>

        <color4>job</color4>.<color3>waitForCompletion</color3>(<color2>true</color2>);
        <color6>return</color6> <color2>0</color2>;
    }
}
</terminal>

다 했으면 컴파일을 합니다.<br>

<terminal>
<strong>[hadoop@namenode airplain]$</strong> javac -cp $HADOOP_HOME/hadoop-core-1.2.1.jar Airline*.java
<strong>[hadoop@namenode airplain]$</strong> jar -cvf $HADOOP_HOME/AirlineCount.jar Airline*.class
<strong>[hadoop@namenode airplain]$</strong> cd $HADOOP_HOME
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop jar AirlineCount.jar AirlineCount airplain airline_count
</terminal>

이번거는 인내심을 가지고 좀 기다리셔야 합니다.<br>
나름 12GB인데 몇십초만에 되진 않거든요.<br>
<br>
다 되고나면 아래 명령어를 입력해주세요.<br>

<terminal>
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop fs -get airline_count/departure-r-00000 departure.txt && ./bin/hadoop fs -get airline_count/arrival-r-00000 arrival.txt
<strong>[hadoop@namenode hadoop]$</strong> mv departure.txt /home/hadoop/hadoop-examples/airplain/ && mv arrival.txt /home/hadoop/hadoop-examples/airplain/
<strong>[hadoop@namenode hadoop]$</strong> cd /home/hadoop/hadoop-examples/airplain/
<strong>[hadoop@namenode airplain]$</strong>
</terminal>

이제 시각화를 진행해봅시다.<br>
터미널에서 R을 실행시켜 진행해보죠.<br>

<terminal>
<strong>[hadoop@namenode airplain]$</strong> R

> library(ggplot2)
> library(dplyr)

다음의 패키지를 부착합니다: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> departure = read.table("departure.txt", header = FALSE, sep = "", col.names = c("year", "month", "departure", "count"))
> arrival = read.table("arrival.txt", header = FALSE, sep = "", col.names = c("year", "month", "arrival", "count"))
> ggplot(data = departure, aes(x = year, y = count)) + geom_line(aes(group = departure, colour = departure)) + scale_x_continuous(breaks=seq(1987, 2008, 1)) + theme(axis.text.x = element_text(angle=60))
</terminal>

<img src="/hadoop/img2/3_2.jpg" alt="">

Oh, My God.... 출발지가 너무너무 많아요...<br>
5개만 뽑아봐요.

<terminal>
> departure[order(departure$count), 3]
.
.
.
[58735] ORD ORD ORD DFW DFW ORD ATL ORD DFW ORD ATL ATL ATL DFW LAX ATL ATL DEN
[58753] LAX ORD ATL ATL ATL DFW ORD ORD ORD ATL ORD DFW ORD ORD ORD DFW ORD ATL
[58771] ORD ATL ORD DFW ATL LAX ATL ATL DFW ORD DFW ORD ATL DFW ORD ATL ORD ATL
[58789] ATL ATL ATL DFW ORD DFW ORD ORD ORD ORD ATL ATL ORD ATL DFW ORD ORD ATL
[58807] DFW ATL ATL ATL ORD ORD ATL ATL ATL ATL ATL ATL DFW ATL ATL ATL ORD ORD
[58825] ORD ATL ATL ATL ATL DFW ORD ORD ATL DFW ORD ORD ORD ATL ATL ORD ATL ATL
[58843] ATL ATL ORD ORD ORD ATL ATL ORD ORD ORD DFW DFW ATL ATL DFW ATL ORD ORD
[58861] ATL ORD ORD ATL ATL ORD ATL ORD ORD ATL ORD ATL ATL ORD ATL ORD ATL ORD
[58879] ORD DFW ORD ATL ATL ATL ORD ORD ATL ORD ATL ATL ATL ATL ATL DFW ATL ORD
[58897] ORD ATL ATL ATL DFW ORD ATL ORD ATL DFW ATL ATL DFW ORD ATL ORD ATL DFW
[58915] ORD ATL ORD ATL ATL ORD ORD ATL ORD ATL ORD ATL ATL ATL DFW ORD ORD ORD
[58933] ATL ATL ATL DFW ATL DFW ATL ORD ATL ORD ATL ATL ATL ATL ORD ORD ATL DFW
[58951] ATL ORD ATL ORD ORD ATL ORD ATL ORD ORD ATL ATL ATL DFW ATL ATL ATL ORD
[58969] ORD ATL ORD ORD ORD ORD ATL ORD ATL ORD DFW ATL ATL ORD ORD ORD ORD ORD
[58987] ORD ORD ORD ORD ORD ATL ORD ATL ATL ATL ORD ATL ORD ATL ORD ORD ORD ORD
[59005] ATL ORD ATL ATL ORD ORD ATL ATL ORD ORD ORD ATL ATL ATL ATL ATL ATL ORD
[59023] ATL ORD ATL ATL ATL ORD ATL ATL ATL ATL ATL ATL ATL
</terminal>

자... 숫자가 많은 순서대로 정렬됐습니다.<br>
많이 보이는걸 뽑아보죠. ATL, ORD, DFW, LAX, DEN... TOP5네요?<br>
그럼 이걸로 통계를 뽑아봅시다.<br>

<terminal>
> dep = departure$departure
> D5 = departure[dep == 'ATL' | dep == 'ORD' | dep == 'DFW' | dep == 'LAX' | dep == 'DEN',]
> ggplot(data = D5, aes(x = month, y = count)) + geom_line(aes(group = year, colour = year)) + facet_wrap(~ departure) + scale_x_continuous(breaks=seq(1, 12, 1))
</terminal>

<img src="/hadoop/img2/3_3.jpg" alt="">

년도가 20개라서 스펙트럼으로 표현되버렸네요... 디테일하게 알아보기는 힘들지만 대충 밝은게 위고, 어두운게 아래라는건 알 수 있습니다.<br>
1999년 부터 2008년도까지 10년치만 뽑으면 좀 더 알기 쉽지 않을까요?<br>

<terminal>
> D5 = departure[dep == 'ATL' & departure$year >= 1999 | dep == 'ORD' & departure$year >= 1999 | dep == 'DFW' & departure$year >= 1999 | dep == 'LAX' & departure$year >= 1999 | dep == 'DEN' & departure$year >= 1999,]
> ggplot(data = D5, aes(x = month, y = count)) + geom_line(aes(group = year, colour = year)) + facet_wrap(~ departure) + scale_x_continuous(breaks=seq(1, 12, 1))
</terminal>

<img src="/hadoop/img2/3_4.jpg" alt="">

음... 여전하군요. 검색해보니 <color4>colour</color4>에 연속된 숫자형 수치가 들어가면 저렇게 스펙트럼으로 나오게 된답니다.<br>
뭐... 어쩔 수 없네요. 그래도 나름 아주 성과가 없었던건 아닙니다.<br>
그래프에 의해면 매년마다 이륙지연 횟수가 늘어난다는 결론을 얻었거든요.<br>
<br>
매 년 늘어난건지 확실히 봅시다. 년도별로 한번 보죠.<br>

<terminal>
> ggplot(data = D5, aes(x = month, y = count)) + geom_line(aes(colour = departure, group = departure)) + scale_x_continuous(breaks=seq(1, 12, 1)) + facet_wrap(~ year)
</terminal>

<img src="/hadoop/img2/3_5.jpg" alt="">

음.... 이렇게 보니 '년도별로 늘어났다' 라는 결론을 내리긴 애매해졌군요.<br>
2000년부터 2002년까지는 줄어들다가 그 뒤에는 늘어나다가 애매해지는 모양새가 되어서요.<br>
좀 더 알려면 더 분석해야겠지만 지금은 일이 아니라 실습이니 그냥 여기까지만 합시다.<br>
<br>
도착지연도 똑같은 과정으로 한번 보도록 하죠<br>

<terminal>
> arrival[order(arrival$count), 3]
.
.
.
[58249] ATL STL DFW IAH LAX ORD ORD ATL ORD ORD ORD ORD DFW ORD ATL DFW ORD ORD
[58267] LAX ORD ORD ORD ORD STL ORD DFW ORD ORD ATL IAH ORD ORD PHX ORD ORD DFW
[58285] STL ORD LAX IAH ORD DFW DFW DFW ORD MSP DFW LAX DFW LAX DTW ORD DFW ORD
[58303] DFW DFW ORD ORD ATL ATL ORD ORD DFW ORD DFW ORD DFW DFW DFW DFW DFW ORD
[58321] ORD ORD DFW DFW ORD LAX STL ORD DFW IAH DFW ORD DFW DFW ORD ATL DFW ORD
[58339] ORD ORD ATL ORD ATL ORD ATL ORD DTW DFW DFW ORD ATL ORD ORD ORD ATL ORD
[58357] ORD ATL ORD DFW DFW DFW ORD ORD DFW ATL ATL LAX LAX ORD ORD ORD ORD DFW
[58375] ORD ORD ATL ORD ATL ATL DFW ORD ORD ORD DFW ATL DEN ATL ORD ORD DFW ORD
[58393] DFW DFW ORD DFW DFW ORD DFW ORD DFW ATL LAX DFW IAH ORD ORD DFW ORD ORD
[58411] LAX ATL ORD DFW DFW DFW IAH DFW ORD ORD DFW ATL DFW ORD ATL ATL ORD IAH
[58429] ORD DFW ATL ATL ORD ORD DFW ATL ATL DFW ATL ATL ATL DFW ORD ORD ATL IAH
[58447] IAH IAH IAH ORD DFW ATL DFW ATL DFW ORD ATL DFW ATL ORD ORD ORD DFW DFW
[58465] ORD ORD ORD ATL DFW ORD ATL ORD DFW ATL ATL ORD DFW ATL DFW DFW ORD ATL
[58483] DFW ATL ATL ORD ATL ATL ATL ORD DFW ATL ORD ORD IAH ATL ORD DFW DFW DFW
[58501] ATL ORD ATL ATL ATL DFW DFW ORD ATL ORD ORD ATL ORD ORD ATL ORD ORD ATL
[58519] DFW ATL ATL ATL ATL ATL ATL ATL ATL ATL ORD ATL ATL ATL ATL ORD ATL ATL
[58537] ATL ATL ATL ATL ORD ATL ATL ATL ATL ATL ATL ATL ATL ATL ATL ATL ATL ATL
[58555] ATL ATL ATL ATL ATL ATL ATL ATL ATL ATL ATL ATL ATL ATL ATL ATL ATL ATL
[58573] ATL ATL ATL ATL ATL ATL
</terminal>

ATL, ORD, DFW, IAH, LAX 이렇게 봅시다.<br>

<terminal>
> arr = arrival$arrival
> A5 = arrival[arr == 'ATL' & arrival$year >= 1999 | arr == 'ORD' & arrival$year >= 1999 | arr == 'DFW' & arrival$year >= 1999 | arr == 'LAX' & arrival$year >= 1999 | arr == 'IAH' & arrival$year >= 1999,]
> ggplot(data = A5, aes(x = month, y = count)) + geom_line(aes(group = year, colour = year)) + facet_wrap(~ arrival) + scale_x_continuous(breaks=seq(1, 12, 1))
</terminal>

<img src="/hadoop/img2/3_6.jpg" alt="">

어라? 여기는 연착횟수가 줄어든 곳도 있네요? 이것도 년도별로 한번 보도록 하죠<br>

<terminal>
> ggplot(data = A5, aes(x = month, y = count)) + geom_line(aes(colour = arrival, group = arrival)) + scale_x_continuous(breaks=seq(1, 12, 1)) + facet_wrap(~ year)
</terminal>

<img src="/hadoop/img2/3_7.jpg" alt="">

지역별로 다른 결과가 나오기는 합니다.<br>
역시나 좀 더 심층적으로 분석하기엔 실습인데 일도 아니고 너무 피곤한 작업이 되지 않을까 싶어 여기서 그만두도록 하겠습니다.<br>
이만큼 해서 우리가 유추해낼 수 있는 정보가 무엇일까요?<br>
<br>
ATL은 하츠필드 잭슨 애틀랜타 국제공항<br>
DEN은 덴버 국제공항<br>
DFW은 댈러스 포트워스 국제공항<br>
등등....
우리가 조사한 지역이 기후가 안좋거나 어느 여러가지 요인에 의에 <color4>이륙과 착륙 둘 다 지연이 자주 된다</color4>는 사실을 알 수 있었습니다.<br>
여기까지 멀티파일로 저장하기와 통계내용을 R을 이용해 여러 각도로 볼 수 있다는 것을 해본 시간이었습니다.<br>
<br>
책에 보면 체인에 대한 내용이 나오는데, 하둡2와 하둡1의 체인은 비슷한데 조금 달라서 그냥 하둡2를 시작하면 그 때 언급하고 보여드리겠습니다.<br>
이번 글은 그럼 여기까지 하겠습니다. 감사합니다.<br>
<br>
<a href="/hadoop/page/2_4.html" onclick="
    event.preventDefault();

    let xhttp = new XMLHttpRequest();

    xhttp.onreadystatechange = () => {
        document.querySelector('main').innerHTML = xhttp.responseText;
    }

    xhttp.open('GET', '/hadoop/page/2_4.html', true);
    xhttp.send();

    document.title = 'Hadoop Guide Part. 2 - Step. 4';
    history.pushState('/hadoop/page/2_4.html' + ' ' + 'Part. 2 - Step. 4', null, '#2_4');

    document.querySelector('side').children[1].classList.add('on');
    document.querySelector('side').children[1].children[3].classList.remove('on');
    document.querySelector('side').children[1].children[4].classList.add('on');
" class="button">다음단계로 가기</a>