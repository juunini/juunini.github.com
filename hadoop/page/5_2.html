<terminal>
wget https://github.com/google/protobuf/releases/download/v3.5.1/protobuf-all-3.5.1.tar.gz && tar -zxvf protobuf-all-3.5.1.tar.gz && rm protobuf-all-3.5.1.tar.gz && cd protobuf-3.5.1 && ./configure && make && sudo make install
wget http://mirror.apache-kr.org/hadoop/common/hadoop-3.0.0/hadoop-3.0.0.tar.gz && tar -zxvf hadoop-3.0.0.tar.gz && rm hadoop-3.0.0.tar.gz
</terminal>

Hadoop 3을 다운로드 받았습니다.<br>
세팅을 합니다.<br>
<br>
<a href="https://github.com/juunini/juunini.github.com/tree/master/hadoop/img5/core-site.xml" target="_new" class="link">core-site.xml</a><br>
<a href="https://github.com/juunini/juunini.github.com/tree/master/hadoop/img5/hdfs-site.xml" target="_new" class="link">hdfs-site.xml</a><br>
<a href="https://github.com/juunini/juunini.github.com/tree/master/hadoop/img5/mapred-site.xml" target="_new" class="link">mapred-site.xml</a><br>
<a href="https://github.com/juunini/juunini.github.com/tree/master/hadoop/img5/yarn-site.xml" target="_new" class="link">yarn-site.xml</a><br>
<a href="https://github.com/juunini/juunini.github.com/tree/master/hadoop/img5/hadoop-env.sh" target="_new" class="link">hadoop-env.sh</a><br>

<terminal>
bin/hdfs namenode -format && sbin/start-dfs.sh && sbin/start-yarn.sh
</terminal>

<terminal>
bin/hdfs dfs -mkdir /user && bin/hdfs dfs -mkdir /user/hadoop && bin/hdfs dfs -put /home/hadoop/webCrawlling/result.txt result.txt
cd
mkdir examples && cd examples && touch WordCountMapper.py && touch WordCountReducer.py && sudo chmod -R 777 *.py
</terminal>

<a href="https://github.com/juunini/juunini.github.com/tree/master/hadoop/img5/WordCountMapper.py" target="_new" class="link">WordCountMapper.py</a><br>
<a href="https://github.com/juunini/juunini.github.com/tree/master/hadoop/img5/WordCountReducer.py" target="_new" class="link">WordCountReducer.py</a><br>

<terminal>
cd && cd hadoop-3.0.0
bin/mapred streaming -input result.txt -output wordcount -mapper /home/hadoop/examples/WordCountMapper.py -reducer /home/hadoop/examples/WordCountReducer.py
bin/hdfs dfs -get wordcount/part-00000 /home/hadoop/webCrawlling/wordcount_result.txt
</terminal>

일단 테스트겸 빠르게 파이썬으로 WordCount를 만들어서 돌려보았습니다.<br>
여담이지만, Hadoop 1.2.1 버전에서는 되지 않았던 파이썬3이 Hadoop 3 버전에는 됩니다. 그래서 파이썬3으로 작성했습니다.<br>
완료되었으니 R로 시각화를 진행해보겠습니다.<br>

<terminal>
sudo R

install.packages("wordcloud")
install.packages("RColorBrewer")

library(wordcloud)
library(RColorBrewer)

wordcount = read.delim("wordcount_result.txt", header = FALSE, sep = "", col.names = c("name", "count"))
wordcount = wordcount[order(-wordcount$count), ]
wordcount = wordcount[1:200, ]
wordcloud(wordcount$name, wordcount$count, random.order = FALSE, random.color = TRUE, colors = brewer.pal(11, "RdBu"), scale = c(5, 0.5), min.freq = 1)
</terminal>

<img src="/hadoop/img5/2_1.jpg" alt="">

....수, 있는, 있다 이런게 제일 많다니.... 제가 원한 결과는 이런게 아닙니다.<br>
조금 힘들더라도 wordcount 전체 목록을 보고 자주 나오는 단어만 추려내어서 워드카운트를 실행하겠습니다.<br>
<br>
보안, 클라우드, 윈도우, 데이터, 구글, 모바일, 서비스, pc, iot, 애플, 네트워크, 소프트웨어, 기업, it, 앱, 안드로이드, 비즈니스, 사용자, 기술, 시스템, 스마트, 인텔, 디지털, 아이폰, 마이크로소프트, 스토리지, 블록체인, 서피스, 성능, 개발, 배터리, ces, 게임, 글로벌, 스마트폰, 애플리케이션, 오픈소스, 온라인, 플랫폼, cpu, 무선, ssd, 아마존, 솔루션, 하드웨어, 인터넷, 미국, ios, 메모리, amd, ai, 컴퓨터, 운영체제, 웹, 오피스, 노트북, 인공지능, 3d, 멜트다운, 머신러닝<br>
<br>
TOP 500을 조회해서 많이 나오는 단어들만 추려냈습니다. 이제 맵리듀스 코드를 고칠 차례입니다.<br>
<a href="https://github.com/juunini/juunini.github.com/tree/master/hadoop/img5/WordCountMapper2.py" target="_new" class="link">WordCountMapper.py</a><br>
<br>

<terminal>
library(wordcloud)
library(RColorBrewer)

wordcount = read.delim("wordcount_result.txt", header = FALSE, sep = "", col.names = c("name", "count"))
wordcloud(wordcount$name, wordcount$count, random.order = FALSE, random.color = TRUE, colors = brewer.pal(3, "Dark2"), scale = c(5, 0.5), min.freq = 1)
</terminal>

<img src="/hadoop/img5/2_2.jpg" alt="">

이제 원하는대로 좀 나온 것 같습니다. 정확한 수치도 한번 확인해보죠.<br>

<terminal>
wordcount[order(-wordcount$count), ]

             name count
8              it  1170
29           보안  1019
19         데이터   934
45           애플   886
32         사용자   818
15           기술   725
16           기업   709
33         서비스   647
57       클라우드   644
46             앱   590
9              pc   584
41         시스템   496
13           구글   489
21 마이크로소프트   482
52         윈도우   434
11           개발   424
55           인텔   402
35           성능   392
36     소프트웨어   374
17       네트워크   354
58         플랫폼   314
7             iot   307
25         모바일   271
44     안드로이드   247
37         솔루션   246
39       스마트폰   245
12           게임   242
43         아이폰   242
31       비즈니스   241
38         스마트   230
30       블록체인   225
4             ces   217
2              ai   180
10            ssd   180
56         컴퓨터   176
40       스토리지   175
50       운영체제   173
5             cpu   170
3             amd   166
20         디지털   162
54         인터넷   159
47       오픈소스   155
42         아마존   154
28         배터리   144
59       하드웨어   139
51             웹   136
23         메모리   128
24       멜트다운   128
6             ios   124
14         글로벌   121
18         노트북   117
27           미국   107
49         온라인   107
34         서피스   104
26           무선    97
48         오피스    92
22       머신러닝    87
53       인공지능    87
1              3d    80
</terminal>

<color2>it</color2>와 <color2>보안</color2>, <color2>데이터</color2>가 압도적으로 높군요.<br>
뭐... itworld는 it전문 뉴스만 올리니 저 단어들이 많이 나올 수 밖에 없습니다. 큰 의미를 못찾겠군요.<br>
<br>
<color2>애플, 사용자, 기술, 서비스, 앱</color2> 이 단어들로 유추해볼 수 있는건 요 근래 애플의 <color4>배터리 게이트</color4> 소동 떄문인 것 같습니다.<br>
<color4>성능저하 업데이트</color4>나 <color4>배터리 게이트</color4>에 대한 언급이나 그것이 고쳐진다거나 하는 뉴스거리가 좀 많았나보군요.<br>
<br>
<color2>클라우드, 서비스, 기술, 마이크로소프트, 아마존, 미국(?)</color2><br>
마이크로소프트는 <color4>azure</color4>, 아마존은 <color4>aws</color4>로 클라우드 서비스를 하는 회사입니다.<br>
아마도 클라우드 서비스나 기술 관련한 기사들이 좀 있었나보군요.<br>
<br>
<color2>마이크로소프트, 서피스, 윈도우, 운영체제, 컴퓨터, 노트북</color2><br>
서피스, 윈도우 모두 마이크로소프트의 제품입니다.<br>
윈도우는 컴퓨터의 운영체제고, 서피스는 노트북입니다.<br>
윈도우, 컴퓨터, 운영체제 이 세가지는 아마도 윈도우의 점유율에 대한 기사에서 나온 것 같고,<br>
서피스는 <color2>서피스 폰</color2>이 나온다거나, 한국에도 정발을 한다거나, <color4>서피스 프로4의 화면 깜빡임 현상</color4> 때문에 기사가 많이 나와서 그런 것 같습니다.<br>
<br>
그 외에는 <color2>인텔, 멜트다운</color2> 사건과, 비트코인떄문에 한창 뜬 기술인 <color2>블록체인</color2>,<br>
<color2>인공지능, 머신러닝, ai, 오픈소스</color2> 이 키워드는 꾸준히 나오는 키워드이구요.<br>
<br>
종합해보자면, 제 입장에서 가장 주목해야 할 키워드는 <color2>보안, 클라우드, iot, 블록체인</color2> 이 정도 인 것 같습니다.<br>
보안은 항상 중요했었고, 클라우드 기술은 4차 산업혁명으로 갈 수록 더더욱 중요해지는 요소입니다.<br>
iot는 5G가 개발되면 개발될수록 점점 우리 생활을 차지해갈테고, 블록체인은 이곳 저곳에서 모두 적용해보려고 탐내는 기술입니다.<br>
<br>
하지만 제가 크롤링 해서 모은 자료는 고작 2018년에 올라온 기사들 뿐입니다.<br>
시간을 좀 많이 들이더라도 2014년 자료부터 모은다면 꽤나 신뢰성 있는 자료를 추출해낼 수 있으리라는 생각이 듭니다.<br>
일단 지금은 실습이지만, 나중에 제대로 분석하는것도 한번 보여드리도록 하겠습니다.<br>
<br>
이번 글은 여기까지고 다음 글에서는 SNS를 크롤링해서 분석해보도록 하겠습니다.<br>
<br>
PS. 아, 까먹고 안한게 있었는데 지금 실험해서 올리도록 하겠습니다.<br>
콤바이너 클래스를 안썼을 때와 썼을 때 비교 입니다.<br>
<br>
안썼을 때<br>
<terminal>
[hadoop@hadoop hadoop-3.0.0]$ bin/mapred streaming -input result.txt -output wordcount -mapper /home/hadoop/examples/WordCountMapper.py -reducer /home/hadoop/examples/WordCountReducer.py
packageJobJar: [] [/home/hadoop/hadoop-3.0.0/share/hadoop/tools/lib/hadoop-streaming-3.0.0.jar] /tmp/streamjob5357208463434533931.jar tmpDir=null
2018-02-08 05:47:55,191 INFO client.RMProxy: Connecting to ResourceManager at hadoop/192.168.247.100:8032
2018-02-08 05:47:55,408 INFO client.RMProxy: Connecting to ResourceManager at hadoop/192.168.247.100:8032
2018-02-08 05:47:55,656 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1518077305546_0012
2018-02-08 05:47:56,241 INFO mapred.FileInputFormat: Total input files to process : 1
2018-02-08 05:47:56,695 INFO mapreduce.JobSubmitter: number of splits:2
2018-02-08 05:47:56,725 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-02-08 05:47:56,818 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1518077305546_0012
2018-02-08 05:47:56,819 INFO mapreduce.JobSubmitter: Executing with tokens: []
2018-02-08 05:47:56,987 INFO conf.Configuration: resource-types.xml not found
2018-02-08 05:47:56,987 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2018-02-08 05:47:57,063 INFO impl.YarnClientImpl: Submitted application application_1518077305546_0012
2018-02-08 05:47:57,124 INFO mapreduce.Job: The url to track the job: http://hadoop:8088/proxy/application_1518077305546_0012/
2018-02-08 05:47:57,125 INFO mapreduce.Job: Running job: job_1518077305546_0012
2018-02-08 05:48:03,245 INFO mapreduce.Job: Job job_1518077305546_0012 running in uber mode : false
2018-02-08 05:48:03,246 INFO mapreduce.Job:  map 0% reduce 0%
2018-02-08 05:48:10,341 INFO mapreduce.Job:  map 50% reduce 0%
2018-02-08 05:48:12,353 INFO mapreduce.Job:  map 100% reduce 0%
2018-02-08 05:48:14,364 INFO mapreduce.Job:  map 100% reduce 100%
2018-02-08 05:48:15,376 INFO mapreduce.Job: Job job_1518077305546_0012 completed successfully
2018-02-08 05:48:15,464 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=245033
		FILE: Number of bytes written=1115546
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2636340
		HDFS: Number of bytes written=774
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=12059
		Total time spent by all reduces in occupied slots (ms)=2320
		Total time spent by all map tasks (ms)=12059
		Total time spent by all reduce tasks (ms)=2320
		Total vcore-milliseconds taken by all map tasks=12059
		Total vcore-milliseconds taken by all reduce tasks=2320
		Total megabyte-milliseconds taken by all map tasks=12348416
		Total megabyte-milliseconds taken by all reduce tasks=2375680
	Map-Reduce Framework
		Map input records=1
		Map output records=19248
		Map output bytes=206531
		Map output materialized bytes=245039
		Input split bytes=186
		Combine input records=0
		Combine output records=0
		Reduce input groups=59
		Reduce shuffle bytes=245039
		Reduce input records=19248
		Reduce output records=59
		Spilled Records=38496
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=221
		CPU time spent (ms)=5720
		Physical memory (bytes) snapshot=923672576
		Virtual memory (bytes) snapshot=8386424832
		Total committed heap usage (bytes)=886571008
		Peak Map Physical memory (bytes)=343457792
		Peak Map Virtual memory (bytes)=2792112128
		Peak Reduce Physical memory (bytes)=237580288
		Peak Reduce Virtual memory (bytes)=2802245632
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2636154
	File Output Format Counters 
		Bytes Written=774
</terminal>

20초<br>
<br>
썼을 때<br>

<terminal>
[hadoop@hadoop hadoop-3.0.0]$ bin/mapred streaming -input result.txt -output wordcount -mapper /home/hadoop/examples/WordCountMapper.py -reducer /home/hadoop/examples/WordCountReducer.py -combiner /home/hadoop/examples/WordCountReducer.py
packageJobJar: [] [/home/hadoop/hadoop-3.0.0/share/hadoop/tools/lib/hadoop-streaming-3.0.0.jar] /tmp/streamjob3068206367845187530.jar tmpDir=null
2018-02-08 06:18:47,690 INFO client.RMProxy: Connecting to ResourceManager at hadoop/192.168.247.100:8032
2018-02-08 06:18:47,914 INFO client.RMProxy: Connecting to ResourceManager at hadoop/192.168.247.100:8032
2018-02-08 06:18:48,161 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hadoop/.staging/job_1518077305546_0013
2018-02-08 06:18:48,340 INFO mapred.FileInputFormat: Total input files to process : 1
2018-02-08 06:18:48,793 INFO mapreduce.JobSubmitter: number of splits:2
2018-02-08 06:18:48,821 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled
2018-02-08 06:18:49,342 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1518077305546_0013
2018-02-08 06:18:49,343 INFO mapreduce.JobSubmitter: Executing with tokens: []
2018-02-08 06:18:49,525 INFO conf.Configuration: resource-types.xml not found
2018-02-08 06:18:49,526 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2018-02-08 06:18:49,611 INFO impl.YarnClientImpl: Submitted application application_1518077305546_0013
2018-02-08 06:18:49,701 INFO mapreduce.Job: The url to track the job: http://hadoop:8088/proxy/application_1518077305546_0013/
2018-02-08 06:18:49,702 INFO mapreduce.Job: Running job: job_1518077305546_0013
2018-02-08 06:18:54,786 INFO mapreduce.Job: Job job_1518077305546_0013 running in uber mode : false
2018-02-08 06:18:54,787 INFO mapreduce.Job:  map 0% reduce 0%
2018-02-08 06:18:59,961 INFO mapreduce.Job:  map 50% reduce 0%
2018-02-08 06:19:03,020 INFO mapreduce.Job:  map 100% reduce 0%
2018-02-08 06:19:07,068 INFO mapreduce.Job:  map 100% reduce 100%
2018-02-08 06:19:07,076 INFO mapreduce.Job: Job job_1518077305546_0013 completed successfully
2018-02-08 06:19:07,166 INFO mapreduce.Job: Counters: 53
	File System Counters
		FILE: Number of bytes read=898
		FILE: Number of bytes written=628462
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=2636340
		HDFS: Number of bytes written=774
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=9148
		Total time spent by all reduces in occupied slots (ms)=3694
		Total time spent by all map tasks (ms)=9148
		Total time spent by all reduce tasks (ms)=3694
		Total vcore-milliseconds taken by all map tasks=9148
		Total vcore-milliseconds taken by all reduce tasks=3694
		Total megabyte-milliseconds taken by all map tasks=9367552
		Total megabyte-milliseconds taken by all reduce tasks=3782656
	Map-Reduce Framework
		Map input records=1
		Map output records=19248
		Map output bytes=206531
		Map output materialized bytes=904
		Input split bytes=186
		Combine input records=19248
		Combine output records=59
		Reduce input groups=59
		Reduce shuffle bytes=904
		Reduce input records=59
		Reduce output records=59
		Spilled Records=118
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=257
		CPU time spent (ms)=3200
		Physical memory (bytes) snapshot=974921728
		Virtual memory (bytes) snapshot=8424353792
		Total committed heap usage (bytes)=879230976
		Peak Map Physical memory (bytes)=364969984
		Peak Map Virtual memory (bytes)=2800832512
		Peak Reduce Physical memory (bytes)=247816192
		Peak Reduce Virtual memory (bytes)=2829238272
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2636154
	File Output Format Counters 
		Bytes Written=774
</terminal>

20초<br>
<br>
시간은 똑같군요.
그렇다면 다른걸로 비교해야겠습니다.<br>

<terminal>
안썼을 때

Map-Reduce Framework
    Map input records=1
    Map output records=19248
    Map output bytes=206531
    Map output materialized bytes=<color6>245039</color6>
    Input split bytes=186
    Combine input records=0
    Combine output records=0
    Reduce input groups=59
    Reduce shuffle bytes=<color6>245039</color6>
    Reduce input records=<color6>19248</color6>
    Reduce output records=59
    Spilled Records=<color6>38496</color6>
    Shuffled Maps =2
    Failed Shuffles=0
    Merged Map outputs=2
    GC time elapsed (ms)=221
    CPU time spent (ms)=<color6>5720</color6>
    Physical memory (bytes) snapshot=923672576
    Virtual memory (bytes) snapshot=8386424832
    Total committed heap usage (bytes)=886571008
    Peak Map Physical memory (bytes)=343457792
    Peak Map Virtual memory (bytes)=2792112128
    Peak Reduce Physical memory (bytes)=237580288
    Peak Reduce Virtual memory (bytes)=2802245632

썼을 때

Map-Reduce Framework
    Map input records=1
    Map output records=19248
    Map output bytes=206531
    Map output materialized bytes=<color6>904</color6>
    Input split bytes=186
    Combine input records=19248
    Combine output records=59
    Reduce input groups=59
    Reduce shuffle bytes=<color6>904</color6>
    Reduce input records=<color6>59</color6>
    Reduce output records=59
    Spilled Records=<color6>118</color6>
    Shuffled Maps =2
    Failed Shuffles=0
    Merged Map outputs=2
    GC time elapsed (ms)=257
    CPU time spent (ms)=<color6>3200</color6>
    Physical memory (bytes) snapshot=974921728
    Virtual memory (bytes) snapshot=8424353792
    Total committed heap usage (bytes)=879230976
    Peak Map Physical memory (bytes)=364969984
    Peak Map Virtual memory (bytes)=2800832512
    Peak Reduce Physical memory (bytes)=247816192
    Peak Reduce Virtual memory (bytes)=2829238272
</terminal>

매퍼 아웃풋의 순간부터 엄청난 수치 변화가 일어나는군요.<br>
리듀서의 부담이 확 줄어드는것이 보입니다. <color4>작게는 100배, 크게는 320배까지</color4> 리듀서의 부담이 줄어듭니다.<br>
게다가 우리는 그냥 단지 20초 라는 똑같은 물리적 시간으로만 느꼈지만, CPU의 입장에서는 <color4>2520ms</color4>라는 큰 차이가 났습니다.(약 2.5초)<br>
<br>
자바 소스로 했으면 좀 더 확실하게 시간차도 느꼈을지도 모르지만, 하둡 스트리밍으로 간단히 테스트해도 이정도의 결과를 도출해낼 수 있었습니다.<br>
하지만, 콤바이너클래스는 어디까지나 메모리의 용량이 충분할 때 사용하는 것이 좋습니다.<br>
끝~<br>