이번 글에서는 조인에 대해 알아보겠습니다.<br>
두 개의 연관이 있는 데이터를 연결시키는 것이 조인입니다.<br>
조인을 실습하기 위해 항공기 이착륙 지연에 사용되었던 내용 중 항공사 코드에 대한 내용을 다운로드 받도록 하겠습니다.<br>
hadoop-examples/airplain 폴더에서 작업해주세요.

<terminal>
<strong>[hadoop@namenode airplain]$</strong> wget http://stat-computing.org/dataexpo/2009/carriers.csv
--2018-01-28 06:39:43--  http://stat-computing.org/dataexpo/2009/carriers.csv
Resolving stat-computing.org (stat-computing.org)... 52.218.128.139
Connecting to stat-computing.org (stat-computing.org)|52.218.128.139|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 43758 (43K) [text/csv]
Saving to: ‘carriers.csv’

100%[======================================>] 43,758       120KB/s   in 0.4s   

2018-01-28 06:39:44 (120 KB/s) - ‘carriers.csv’ saved [43758/43758]

<strong>[hadoop@namenode airplain]$</strong> sed -e '1d' carriers.csv > carries_new.csv
<strong>[hadoop@namenode airplain]$</strong> mv carries_new.csv carriers.csv
<strong>[hadoop@namenode airplain]$</strong> cd $HADOOP_HOME
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop fs -put /home/hadoop/hadoop-examples/airplain/carriers.csv ./
<strong>[hadoop@namenode hadoop]$</strong> cd /home/hadoop/hadoop-examples/airplain
<strong>[hadoop@namenode airplain]$</strong> rm carriers.csv
</terminal>

HDFS로 복사가 완료되었습니다.<br>
조인에는 맵 사이드 조인과 리듀스 사이드 조인이 있습니다.<br>
맵 사이드 조인은 상대적으로 저용량 파일을 조인할 때 사용합니다.<br>
리듀스 사이드 조인은 대용량 파일을 조인할 때 사용하고요.<br>
먼저 맵 사이드 조인부터 해보겠습니다.<br>
맵 사이드 조인은 이름답게 리듀서를 실행하지 않습니다.<br>
<br>
작업은 hadoop-examples폴더에 mapSideJoin 이라는 폴더 안에서 작업하겠습니다.<br>
우선 다른 폴더에서 AirlineParser.java 파일을 복사해서 넣어주세요.<br>
<br>
아.... 시작하려고 보니 책에는 CarrierCodeParser 라는 클래스 파일을 import 하라고 했는데 책 어딜 봐도 없습니다.<br>
휴우... 없어서 인터넷에 뒤지니 출판사에서 올린 깃허브에 있기는 있군요...<br>
<br>
<color4>CarrierCodeParser.java</color4>

<terminal>
<color4>package</color4> <color2>Airline</color2>;

<color4>import</color4> <color2>org.apache.hadoop.io.Text</color2>;

<color2>public</color2> <color2>class</color2> CarrierCodeParser {
  <color2>private</color2> <color2>String</color2> carrierCode;
  <color2>private</color2> <color2>String</color2> carrierName;
  <blur><i>// 코드네임과 풀 네임은 당연히 문자열이지요?</i></blur>

  <color2>public</color2> <color3>CarrierCodeParser</color3>(<color2>Text</color2> value) {
    <color4>this</color4>(<color4>value</color4>.<color3>toString</color3>()); <blur><i>// 이 클래스를 실행시킬 때 value값을 넣어주면 문자열로 변환시켜 읽어들입니다.</i></blur>
  }

  <color2>public</color2> <color3>CarrierCodeParser</color3>(<color2>String</color2> value) {  <blur><i>// 문자열로 변환된 value값을 넣어주면 콤마를 기준으로 배열로 쪼개버립니다.</i></blur>
    <color6>try</color6> {
      <color2>String</color2>[] colums = <color4>value</color4>.<color3>replaceAll</color3>(<color7>"\""</color7>, <color7>""</color7>).<color3>split</color3>(<color7>","</color7>);   <blur><i>// 여기에 코드를 좀 추가했습니다. replaceAll을 추가했는데, 쌍따옴표를 전부 제거하는겁니다. 안그러면 항공사 코드를 다른 문자열로 인식해버려서요.</i></blur>
      <color6>if</color6> (colums <color2>!= null &&</color2> <color4>colums</color4>.length <color2>> 0</color2>) {
        carrierCode = colums[<color2>0</color2>];
        carrierName = colums[<color2>1</color2>];
      }
    } <color6>catch</color6> (<color2>Exception</color2> e) {
      <color4>System</color4>.<color4>out</color4>.<color3>println</color3>(<color7>"Error parsing a record :"</color7> + <color4>e</color4>.<color3>getMessage</color3>());
    }
  }

  <color2>public</color2> <color2>String</color2> <color3>getCarrierCode</color3>() {
    <color6>return</color6> carrierCode;
  }

  <color2>public</color2> <color2>String</color2> <color3>getCarrierName</color3>() {
    <color6>return</color6> carrierName;
  }
}
</terminal>

<color4>MapSideJoinMapper.java</color4>

<terminal>
<color4>package</color4> <color2>Airline</color2>;

<color4>import</color4> <color2>java.io.BufferedReader</color2>;
<color4>import</color4> <color2>java.io.FileReader</color2>;
<color4>import</color4> <color2>java.io.IOException</color2>;
<color4>import</color4> <color2>java.util.Hashtable</color2>;

<color4>import</color4> <color2>org.apache.hadoop.filecache.DistributedCache</color2>;
<color4>import</color4> <color2>org.apache.hadoop.fs.Path</color2>;
<color4>import</color4> <color2>org.apache.hadoop.io.LongWritable</color2>;
<color4>import</color4> <color2>org.apache.hadoop.io.Text</color2>;
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.Mapper</color2>;

<color4>import</color4> <color2>Airline.AirlineParser</color2>;
<color4>import</color4> <color2>Airline.CarrierCodeParser</color2>;

<color2>public</color2> <color2>class</color2> MapSideJoinMapper <color2>extends</color2> <color4>Mapper</color4>&lt;<color2>LongWritable</color2>, <color2>Text</color2>, <color2>Text</color2>, <color2>Text</color2>&gt; {   <blur><i>// 조인 할 것이기 때문에 key인 줄 번호만 Long으로 받고 나머지는 Text로</i></blur>

    <color2>private</color2> <color2>Hashtable</color2>&lt;<color2>String</color2>, <color2>String</color2>&gt; joinMap = <color6>new</color6> <color2>Hashtable</color2>&lt;<color2>String</color2>, <color2>String</color2>&gt;();

    <color2>private</color2> <color2>Text</color2> outputKey = <color6>new</color6> <color3>Text</color3>();

    <color2>@Override</color2>
    <color2>public</color2> <color2>void</color2> <color3>setup</color3>(<color2>Context</color2> context) <color2>throws</color2> <color2>IOException</color2>, <color2>InterruptedException</color2> {
        <color6>try</color6> {

            <color2>Path</color2>[] cacheFiles = <color4>DistributedCache</color4>.<color3>getLocalCacheFiles</color3>(<color4>context</color4>.<color3>getConfiguration</color3>());   <blur><i>// 파일을 읽어서 분산처리 합니다.</i></blur>

            <color6>if</color6> (cacheFile <color2>!= null &&</color2> <color4>cacheFiles</color4>.length <color2>> 0</color2>) {

                <color2>String</color2> line;
                <color2>BufferedReader</color2> br = <color6>new</color6> <color3>BufferedReader</color3>(<color6>new</color6> <color3>FileReader</color3>(cacheFiles[<color2>0</color2>].<color3>toString</color3>()));    <blur><i>// 분산처리 된 파일을 한줄씩 읽어옴.</i></blur>

                <color6>try</color6> {
                    <color6>while</color6> ((line = <color4>br</color4>.<color3>readLine</color3>()) <color2>!= null</color2>) {    <blur><i>// 더 이상 남은 줄이 없을 때 까지</i></blur>
                        <color2>CarrierCodeParser</color2> codeParser = <color6>new</color6> <color3>CarrierCodeParser</color3>(line);
                        <color4>joinMap</color4>.<color3>put</color3>(<color4>codeParser</color4>.<color3>getCarrierCode</color3>(), <color4>codeParser</color4>.<color3>getCarrierName</color3>());
                    }
                } <color6>finally</color6> {
                    <color4>br</color4>.<color3>close</color3>();
                }
            }

        } <color6>catch</color6> (<color2>IOException</color2> e) {
            <color4>e</color4>.<color3>printStackTrace</color3>();
        }
    }

    <color2>public</color2> <color2>void</color2> <color3>map</color3>(<color2>LongWritable</color2> key, <color2>Text</color2> value, <color2>Context</color2> context) <color2>throws</color2> <color2>IOException</color2>, <color2>InterruptedException</color2> {

        <color2>AirlineParser</color2> parser = <color6>new</color6> <color3>AirlineParser</color3>(value);
        <color4>outputKey</color4>.<color3>set</color3>(<color4>parser</color4>.<color3>getUniqueCarrier</color3>());
        <color4>context</color4>.<color3>write</color3>(outputKey, <color6>new</color6> <color3>Text</color3>(<color4>joinMap</color4>.<color3>get</color3>(<color4>parser</color4>.<color3>getUniqueCarrier</color3>()) + <color7>"\t"</color7> + <color4>value</color4>.<color3>toString</color3>()));

    }
}
</terminal>

<color4>MapSideJoin.java</color4>

<terminal>
<color4>package</color4> <color2>Airline</color2>;

<color4>import</color4> <color2>org.apache.hadoop.conf.Configuration</color2>;
<color4>import</color4> <color2>org.apache.hadoop.conf.Configured</color2>;
<color4>import</color4> <color2>org.apache.hadoop.filecache.DistributedCache</color2>;
<color4>import</color4> <color2>org.apache.hadoop.fs.Path</color2>;
<color4>import</color4> <color2>org.apache.hadoop.io.Text</color2>;
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.Job</color2>;
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.lib.input.FileInputFormat</color2>;
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.lib.input.TextInputFormat</color2>;
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.lib.output.FileOutputFormat</color2>;
<color4>import</color4> <color2>org.apache.hadoop.mapreduce.lib.output.TextOutputFormat</color2>;
<color4>import</color4> <color2>org.apache.hadoop.util.GenericOptionsParser</color2>;
<color4>import</color4> <color2>org.apache.hadoop.util.Tool</color2>;
<color4>import</color4> <color2>org.apache.hadoop.util.ToolRunner</color2>;

<color2>public</color2> <color2>class</color2> MapSideJoin <color2>extends</color2> <color4>Configured</color4> <color2>implements</color2> <color4>Tool</color4> {

    <color2>public</color2> <color2>int</color2> <color3>run</color3>(<color2>String</color2>[] args) <color2>throws</color2> <color2>Exception</color2> {
        <color2>String</color2>[] otherArgs = <color6>new</color6> <color3>GenericOptionParser</color3>(<color3>getConf</color3>(), args).<color3>getRemainingArgs</color3>();

        <color6>if</color6> (<color4>otherArgs</color4>.length <color2>!= 3</color2>) {    <blur><i>// 배열이 3개가 들어와야 함</i></blur>
            <color4>System</color4>.<color4>err</color4>.<color3>println</color3>(<color7>"Usage: MapSideJoin [metadata] [in] [out]"</color7>); <blur><i>조인 할 데이터, 데이터, 아웃풋</i></blur>
            <color4>System</color4>.<color3>exit</color3>(<color2>2</color2>);
        }

        <color2>Job</color2> job = <color6>new</color6> <color3>Job</color3>(<color3>getConf</color3>(), <color7>"MapSideJoin"</color7>);

        <color4>DistributedCache</color4>.<color3>addCacheFile</color3>(<color6>new</color6> <color3>Path</color3>(otherArgs[<color2>0</color2>]).<color3>toUri</color3>(), <color4>job</color4>.<color3>getConfiguration</color3>());  <blur><i>// 분산 캐시 설정</i></blur>

        <color4>FileInputFormat</color4>.<color3>addInputPath</color3>(job, <color6>new</color6> <color3>Path</color3>(otherArgs[<color2>1</color2>]));
        <color4>FileOutputFormat</color4>.<color3>setOutputPath</color3>(job, <color6>new</color6> <color3>Path</color3>(otherArgs[<color2>2</color2>]));

        <color4>job</color4>.<color3>setJarByClass</color3>(<color4>MapSideJoin</color4>.class);
        <color4>job</color4>.<color3>setMapperClass</color3>(<color4>MapSideJoinMapper</color4>.class);
        <color4>job</color4>.<color3>setNumReduceTasks</color3>(<color2>0</color2>);   <blur><i>// 리듀서 사용 안함</i></blur>

        <color4>job</color4>.<color3>setInputFormatClass</color3>(<color4>TextInputFormat</color4>.class);
        <color4>job</color4>.<color3>setOutputFormatClass</color3>(<color4>TextOutputFormat</color4>.class);

        <color4>job</color4>.<color3>setOutputKeyClass</color3>(<color4>Text</color4>.class);
        <color4>job</color4>.<color3>setOutputValueClass</color3>(<color4>Text</color4>.class);

        <color4>job</color4>.<color3>waitForCompletion</color3>(<color2>true</color2>);
        <color6>return</color6> 0;
    }

    <color2>public</color2> <color2>static</color2> <color2>void</color2> <color3>main</color3>(<color2>String</color2>[] args) <color2>throws</color2> <color2>Exception</color2> {
        <color2>int</color2> res = <color4>ToolRunner</color4>.<color3>run</color3>(<color6>new</color6> <color3>Configuration</color3>(), <color6>new</color6> <color3>MapSideJoin</color3>(), args);
        <color4>System</color4>.<color4>out</color4>.<color3>println</color3>(<color7>"## RESULT : "</color7> + res);
    }
}
</terminal>

컴파일 하고 실행해봅시다.<br>

<terminal>
<strong>[hadoop@namenode mapSideJoin]$</strong> javac -cp $HADOOP_HOME/hadoop-core-1.2.1.jar:$HADOOP_HOME/lib/commons-cli-1.2.jar -d . *.java
<strong>[hadoop@namenode mapSideJoin]$</strong> jar -cvf $HADOOP_HOME/MapSideJoin.jar ./Airline/*.class
Manifest를 추가함
추가하는 중: Airline/AirlineParser.class(입력 = 2223) (출력 = 1079)(51%를 감소함)
추가하는 중: Airline/MapSideJoin.class(입력 = 2677) (출력 = 1267)(52%를 감소함)
추가하는 중: Airline/MapSideJoinMapper.class(입력 = 3307) (출력 = 1365)(58%를 감소함)
<strong>[hadoop@namenode mapSideJoin]$</strong> cd $HADOOP_HOME
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop jar MapSideJoin.jar Airline.MapSideJoin carriers.csv airplain/2008.csv map_join
.
.
.
18/01/28 07:40:31 INFO mapred.JobClient:  map 100% reduce 0%
18/01/28 07:40:31 INFO mapred.JobClient: Job complete: job_201801272358_0015
18/01/28 07:40:31 INFO mapred.JobClient: Counters: 19
18/01/28 07:40:31 INFO mapred.JobClient:   Map-Reduce Framework
18/01/28 07:40:31 INFO mapred.JobClient:     Spilled Records=0
.
.
.
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop fs -ls map_join
Found 13 items
-rw-r--r--   3 hadoop supergroup          0 2018-01-28 07:40 /user/hadoop/map_join/_SUCCESS
drwxr-xr-x   - hadoop supergroup          0 2018-01-28 07:39 /user/hadoop/map_join/_logs
-rw-r--r--   3 hadoop supergroup   87401259 2018-01-28 07:39 /user/hadoop/map_join/part-m-00000
-rw-r--r--   3 hadoop supergroup   87045872 2018-01-28 07:39 /user/hadoop/map_join/part-m-00001
-rw-r--r--   3 hadoop supergroup   88157694 2018-01-28 07:39 /user/hadoop/map_join/part-m-00002
-rw-r--r--   3 hadoop supergroup   88954716 2018-01-28 07:39 /user/hadoop/map_join/part-m-00003
-rw-r--r--   3 hadoop supergroup   87780517 2018-01-28 07:40 /user/hadoop/map_join/part-m-00004
-rw-r--r--   3 hadoop supergroup   87481529 2018-01-28 07:40 /user/hadoop/map_join/part-m-00005
-rw-r--r--   3 hadoop supergroup   87195853 2018-01-28 07:40 /user/hadoop/map_join/part-m-00006
-rw-r--r--   3 hadoop supergroup   87122067 2018-01-28 07:40 /user/hadoop/map_join/part-m-00007
-rw-r--r--   3 hadoop supergroup   86756011 2018-01-28 07:40 /user/hadoop/map_join/part-m-00008
-rw-r--r--   3 hadoop supergroup   89365213 2018-01-28 07:40 /user/hadoop/map_join/part-m-00009
-rw-r--r--   3 hadoop supergroup   23207941 2018-01-28 07:40 /user/hadoop/map_join/part-m-00010
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop fs -cat map_join/part-m-00000 | head -10
WN    Southwest Airlines Co.    2008,1,3,4,2003,1955,2211,2225,WN,335,N712SW,128,150,116,-14,8,IAD,TPA,810,4,8,0,,0,NA,NA,NA,NA,NA
WN    Southwest Airlines Co.    2008,1,3,4,754,735,1002,1000,WN,3231,N772SW,128,145,113,2,19,IAD,TPA,810,5,10,0,,0,NA,NA,NA,NA,NA
WN    Southwest Airlines Co.    2008,1,3,4,628,620,804,750,WN,448,N428WN,96,90,76,14,8,IND,BWI,515,3,17,0,,0,NA,NA,NA,NA,NA
WN    Southwest Airlines Co.    2008,1,3,4,926,930,1054,1100,WN,1746,N612SW,88,90,78,-6,-4,IND,BWI,515,3,7,0,,0,NA,NA,NA,NA,NA
WN    Southwest Airlines Co.    2008,1,3,4,1829,1755,1959,1925,WN,3920,N464WN,90,90,77,34,34,IND,BWI,515,3,10,0,,0,2,0,0,0,32
WN    Southwest Airlines Co.    2008,1,3,4,1940,1915,2121,2110,WN,378,N726SW,101,115,87,11,25,IND,JAX,688,4,10,0,,0,NA,NA,NA,NA,NA
WN    Southwest Airlines Co.    2008,1,3,4,1937,1830,2037,1940,WN,509,N763SW,240,250,230,57,67,IND,LAS,1591,3,7,0,,0,10,0,0,0,47
WN    Southwest Airlines Co.    2008,1,3,4,1039,1040,1132,1150,WN,535,N428WN,233,250,219,-18,-1,IND,LAS,1591,7,7,0,,0,NA,NA,NA,NA,NA
WN    Southwest Airlines Co.    2008,1,3,4,617,615,652,650,WN,11,N689SW,95,95,70,2,2,IND,MCI,451,6,19,0,,0,NA,NA,NA,NA,NA
WN    Southwest Airlines Co.    2008,1,3,4,1620,1620,1639,1655,WN,810,N648SW,79,95,70,-16,0,IND,MCI,451,3,6,0,,0,NA,NA,NA,NA,NA
cat: Unable to write to output stream.
</terminal>

요렇게 항공사 코드와 항공사의 풀네임을 조인시켜줍니다.<br>
맵 사이드 조인은 부분 정렬 처럼 상대적으로 작은 용량의 데이터를 조인하는데에 좋습니다.<br>
좀 더 용량이 커지면 리듀스 사이드 조인을 해야합니다.<br>
제 개인적인 경험과 생각이지만 아마도 20GB기준으로 속도의 차이가 조금씩 나기 시작하는 것 같습니다.<br>
다음 글에서는 리듀스 사이드 조인을 다루도록 하겠습니다.<br>
<br>
<a href="/hadoop/page/2_8.html" onclick="
    event.preventDefault();

    let xhttp = new XMLHttpRequest();

    xhttp.onreadystatechange = () => {
        document.querySelector('main').innerHTML = xhttp.responseText;
    }

    xhttp.open('GET', '/hadoop/page/2_8.html', true);
    xhttp.send();

    document.title = 'Hadoop Guide Part. 2 - Step. 8';
    history.pushState('/hadoop/page/2_8.html' + ' ' + 'Part. 2 - Step. 8', null, '#2_8');

    document.querySelector('side').children[1].classList.add('on');
    document.querySelector('side').children[1].children[7].classList.remove('on');
    document.querySelector('side').children[1].children[8].classList.add('on');
" class="button">다음단계로 가기</a>